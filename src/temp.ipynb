{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import get_args, eval\n",
    "from data.transformations import make_train_transforms, val_transforms\n",
    "import clip\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.winoground import WinogroundDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset winoground (/home/samuelyu/.cache/huggingface/datasets/facebook___winoground/default/0.0.0/72585f4d9cd5a28790bb9bc2adbdd45633f36dfbf85df529e0756e114e134285)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1321.04it/s]\n",
      "Found cached dataset winoground (/home/samuelyu/.cache/huggingface/datasets/facebook___winoground/default/0.0.0/72585f4d9cd5a28790bb9bc2adbdd45633f36dfbf85df529e0756e114e134285)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1346.05it/s]\n",
      "Found cached dataset winoground (/home/samuelyu/.cache/huggingface/datasets/facebook___winoground/default/0.0.0/72585f4d9cd5a28790bb9bc2adbdd45633f36dfbf85df529e0756e114e134285)\n",
      "100%|██████████| 1/1 [00:00<00:00, 1321.04it/s]\n"
     ]
    }
   ],
   "source": [
    "train = WinogroundDataset(transform=make_train_transforms(None, None), split=\"train\", ratio=0.5)\n",
    "val = WinogroundDataset(transform=val_transforms, split=\"test\", ratio=0.5)\n",
    "test = WinogroundDataset(transform=val_transforms, split=\"test\", ratio=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train, batch_size=2, shuffle=False)\n",
    "val_dataloader = DataLoader(val, batch_size=2, shuffle=False)\n",
    "test_dataloader = DataLoader(test, batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess = clip.load(\"ViT-B/32\", device=\"cuda\")\n",
    "model = model.float()\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "        # if \"11\" in name or \"ln_post\" in name or \"ln_final\" in name:\n",
    "        if \"position\" in name:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_image = nn.CrossEntropyLoss()\n",
    "loss_text = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-8)\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181.6078570218524, 48, 130, 400)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(val_dataloader, model, loss_image, loss_text, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376.8845534691354, 84, 244, 800)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(test_dataloader, model, loss_image, loss_text, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = 0\n",
    "train_correct_image = 0\n",
    "train_correct_text = 0\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    image = batch['image'].cuda()\n",
    "    text = batch['text'].cuda().squeeze(1)\n",
    "    num_image = len(batch['image'])\n",
    "\n",
    "    image_features, text_features = model(image, text)\n",
    "    logits_per_image = 100.0 * image_features @ text_features.t()\n",
    "    logits_per_text = logits_per_image.t()\n",
    "    loss_i = loss_image(logits_per_image, torch.arange(len(batch['image'])).cuda())\n",
    "    loss_t = loss_text(logits_per_text, torch.arange(len(batch['image'])).cuda())\n",
    "\n",
    "    total_loss = (loss_i + loss_t) / 2\n",
    "    total_loss.backward()\n",
    "    train_loss += total_loss.item()\n",
    "\n",
    "    train_correct_text += ((logits_per_image.argmax(dim=1) == torch.arange(len(batch['image'])).cuda()).sum().item() == len(batch['image']))*len(batch['image'])\n",
    "    train_correct_image += ((logits_per_text.argmax(dim=1) == torch.arange(len(batch['image'])).cuda()).sum().item() == len(batch['image']))*len(batch['image'])\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4999073280068114, 0.52, 0.605)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss/400, train_correct_image/400, train_correct_text/400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('winoground')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c77539f7a5afcb44bb1dadb52a34ceea8e3af56634fd66545ab473609bb8c1d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
